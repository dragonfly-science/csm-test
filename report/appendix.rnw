\newpage

\section{Data sources}
\label{app:literature}

\subsection{Sentinel 2}

Compared to Landsat multispectral bands, the Sentinel-2 bands (\autoref{tab:sentinel2}) provide three red-edge bands and one NIR band with improved spatial resolution. The Sentinel 2 bands can be used to derive various vegetation indices useful for discriminating between species and estimating forest biomass. SNAP is an open source common architecture for ESA Toolboxes ideal for the exploitation of Earth Observation data \footnote{Available here: \url{https://step.esa.int/main/toolboxes/snap/}}. The software provides toolboxes to derive information (e.g. vegetation indices) from Sentinel data.

\begin{center}
\begin{small}
\begin{table}[hbp]
  \caption{Overview of Sentinel-2 bands\protect\footnotemark}
  \label{tab:sentinel2}
  \begin{center}
  \begin{tabular}{clrr}
    Band & Description & Wavelength (µm) & Resolution (m) \tabularnewline
    \addlinespace
    1 & Coastal Aerosol & 0.433 - 0.453 &  60 \\ 
    2 & Blue & 0.458 - 0.523 &  10 \\ 
    3 & Green & 0.543 - 0.578 &  10 \\ 
    4 & Red & 0.650 - 0.680 &  10 \\ 
    5 & RE1 & 0.698 - 0.713 &  20 \\ 
    6 & RE2 & 0.733 - 0.748 &  20 \\ 
    7 & RE3 & 0.773 - 0.793 &  20 \\ 
    8 & NIR & 0.785 - 0.900 &  10 \\ 
    8a & Narrow NIR & 0.855 - 0.875 &  20 \\ 
    9 & Water vapour & 0.935 - 0.955 &  60 \\ 
    10 & SWIR-Cirrus & 1.365 - 1.385 &  60 \\ 
    11 & SWIR-1 & 1.565 - 1.655 &  20 \\ 
    12 & SWIR-2 & 2.100 - 2.280 &  20 \\
  \end{tabular}
\end{center}
\end{table}
\end{small}
\footnotetext{Available here: \url{https://www.arcgis.com/home/item.html?id=fd61b9e0c69c4e14bebd50a9a968348c}}
\end{center}

\newpage

\subsubsection{Vegetation Indices} 

Vegetation indices (\autoref{tab:vegindices}) can be calculated readily using individual Sentinel-2 or Landsat bands. based on near-infrared wavelengths have weaker relationships with biomass than those including shortwave-infrared wavelengths, especially for forest sites with complex stand structures \citep{lu_survey_2016}. The results for vegetation indices may show stronger relationships with biomass than individual spectral bands, somehow independent of different biophysical conditions. However, in a study area with poor soil conditions and relatively simple forest stand structure, near-infrared band or relevant vegetation indices had a strong relationship with biomass \citep{lu_survey_2016}.

Papers:

Estimating AGB in sub-tropical Nepal using Sentinel 2 \citep{pandit_estimating_2018}. Field-based AGB as a dependent variable, using spectral band values and spectral-derived vegetation indices as independent variables in a 'Random Forest' (RF) machine-learning approach \citep{breiman_random_2001}. In this algorithm, decision trees are generated to the maximum extent without pruning using a randomly-selected two thirds of the samples as training data with bootstrapping (re-sampling the data many times with replacement), which strengthens the flexibility by aggregating the prediction across individual trees to make a final prediction. The paper ranks importance of spectral band data and vegetation indices as a typical output of a RF to estimate AGB (R² = 0.81 and RMSE = 25.57 t ha$^{-1}$; \cite{pandit_estimating_2018}.

Estimating AGB in in tropical forest using Sentinel-1 (SAR) and vegetation indices from Sentinel-2 \citep{ghosh_aboveground_2018}. Sentinel-1 data does not work as a good predictor variable for the study area, as C-band SAR backscatter saturates at a biomass densities exceeding 100 Mg ha$^{-1}$. R package, CARET was used to implement RF regression to rank important predictor variables. Stochastic gradient boosting modelling (SGB, same R package) combines both regression tree and boosted algorithms to predict the response variable. SGB models were fitted, with varying values for the number of regression trees (50 – 5000), tree complexity of 1, 3 and 5. The value for learning rate was fixed at 0.01. Combination of satellite sensors shows the best result for \textit{S. robusta} forest, with a coefficient of determination value of 0.71 and an RMSE value of 105.027 t ha$^{-1}$ \citep{ghosh_aboveground_2018}.

\newpage

\begin{landscape}
\begin{small}
\begin{table}[hbp]
  \caption{Vegetation Indices derived from Sentinel 2 information (adapted from Pandit
et al. 2018, Wang et al. 2020)}
  \label{tab:vegindices}
  \begin{scriptsize}
  \begin{center}  
  \begin{tabular}{llr}
    Vegetation Indices & Equations & References \tabularnewline
    \addlinespace
    NDVI &	(NIR - Red)/(NIR + Red) &	\citep{tucker_red_1979}	\\
    RGR (Red Green Ratio) &	Red / Green &	\citep{sims_relationships_2002} \\		
    EVI (Enhanced Vegetation Index) &	2.5*((NIR - Red)/ (NIR + 1 + 6 * Red + 7.5 * Blue)) &	\citep{huete_overview_2002} \\
    SR (Simple ratio) &	NIR/RED & \citep{jordan_derivation_1969, wicaksono_mangrove_2016}	\\	
    SAVI (Soil-Adjusted Vegetation Index) &	(NIR - Red)/(NIR + Red + L)* (1 + L) &	\citep{huete_soil-adjusted_1988}	\\
    DVI &	NIR - Red &	\citep{zhu_exploring_2017} \\
    FDI (Forest Discrimination Index) &	NIR - (Green + Red) &	\citep{kamal_object-based_2015} \\
    TNDVI (Transformed Normal Difference vegetation index) &	sqrt[(NIR - Red)/(NIR + Red) + 0.5] &	\citep{castillo_estimation_2017} \\
    Red edge based				
    PSRI (Plant Senescence Reflectance Index) &	(Red - Green)/RE2 &	\citep{hill_vegetation_2013, merzlyak_non-destructive_1999}	\\
    RE NDVI &	 (NIR- RE2)/(NIR + RE2)	& \citep{sharma_active-optical_2015} \\
    NDVI1 &	(NIR - RE1)/(NIR + RE1) &	\citep{kross_assessment_2015} \\	
    NDVI2 &	(NIR - RE2)/(NIR + RE2) & \citep{gitelson_spectral_1994, kross_assessment_2015}	\\
    NDVI3 &	(NIR - RE3)/(NIR + RE3) & \citep{sharma_active-optical_2015} \\
    NDVI4 &	(NIR - RE4)/(NIR + RE4) &	\citep{kross_assessment_2015} \\
    Clg-RE1\footnote{Subtraction of NIR reciprocal reflectance from from reciprocal reflectance (520 to 550 nm and 695 to 705) relates closely to total chlorophyll content \citep{gitelson_relationships_2003}} &	RE1 / Green - 1 &	\citep{gitelson_relationships_2003}	\\
    Clg-RE2 &	RE2 / Green - 1 &	\citep{gitelson_relationships_2003}	\\	
    Clg-RE3 &	RE3 / Green - 1 &	\citep{gitelson_relationships_2003}	\\		
    IRECI (Inverted Red-Edge Chlorophyll Index\footnote{IRECI had highest correlation to biomass (r = 0.8) in a Mangrove Forest (Philippines, \cite{castillo_estimation_2017}) and further improved by supplementing elevation information}) &	(RE3 - Red)/(RE1/RE2) &	\citep{castillo_estimation_2017} \\	
    MTCI (terrestrial chlorophyll index) &	RE2 - RE1)/(RE1 - Red) &	\citep{dash_meris_2004}	\\
    MCARI (modified chlorophyll absorption in reflectance index) &	[(RE1 - Red) - 0.2 * (RE1 - Green)]×(RE1/Red) &	\citep{daughtry_estimating_2000} \\		
    MSRren (Modified Simple Ratio red-edge narrow) &	[(RE4 / RE1) - 1] / sqrt[(RE4 / RE1) + 1] &	\citep{fernandez-manso_sentinel-2a_2016} \\		
    PSSRa (pigment specific simple ratio) &	RE3 / Red &	\citep{blackburn_spectral_1998}	\\
    S2REP (Sentinel-2-red-edge position) &	RE1 + 35*(0.5*(RE3 + Red)/2) - RE1)/(RE2 -RE1)] &	 \citep{frampton_evaluating_2013} \\
    RECI (Inverted Red-Edge Chlorophyll Index) &	NIR - Red/(RE1/RE2)	& \citep{frampton_evaluating_2013} \\
    Shortwave infrared based\footnote{SWIR bands are used as important indicators in forest regeneration studies \citep{boonprong_random_2018} and raw bands are useful for vegetation mapping \citep{immitzer_first_2016}. Large changes for seasonal reflectance have been identified for European forest species \citep{grabska_forest_2019}}			
    NDII (Normalized Difference Infrared Index) &	(NIR - SWIR1)/(NIR + SWIR1) &	\citep{hardisky_influence_1983}	\\
    MNDWI (Normalised difference water index\footnote{The water index can be used to elineate water bodies \citep{ji_analysis_2009}}) &	 (Green-SWIR1)/(Green + SWIR1) &	\citep{ji_analysis_2009} \\
  \end{tabular}
  \end{center}  
\end{scriptsize}
\end{table}
\end{small}
\end{landscape}

\newpage

\subsubsection{Normalized Burn Ratio} 

The Normalized Burn Ratio (NBR) is an index designed to highlight burnt areas in large fire zones and can be derived from Landsat or Sentinel imagery. The formula is similar to NDVI (\autoref{eq:nbr}), except that it combines near infrared (NIR) and shortwave infrared (SWIR) wavelengths (\autoref{fig:nbr-overview}). It can also be used to monitor forest disturbances such as logging activities \citep{shimizu_using_2016}. A high NBR value indicates healthy vegetation while a low value indicates bare ground and recently burnt areas. Non-burnt areas are normally attributed to values close to zero.

\begin{equation}
NBR = (NIR-SWIR)/(NIR+SWIR)
\label {eq:nbr}
\end{equation}

For any burn related damage/regeneration calculations we can verify fire activity locations via the Fire Information for Resource Management System (FIRMS\footnote{Available here: \url{https://firms.modaps.eosdis.nasa.gov/download/}}). The data come from the Collection 6 Near Real Time (NRT), extracted from the standard MCD14ML fire product produced at the MODIS Fire Science Computing Facility \citep{roteta_development_2019}.

\begin{figure}[ht]
\begin{center}
 \label{fig:nbr-overview}
 \includegraphics[scale=1.0]{../figures/nbr.jpg}
 \caption{Comparison of the spectral response of healthy vegetation and burned areas (USFS)}
\end{center}
\end{figure}

Papers:

Sentinel 2 data to create fire database in sub-Saharan Africa (Roteta et al., 2019). Sentinel-2 MSI reflectance measurements in the short and near infrared wavebands plus the active fires detected by Terra and Aqua MODIS sensor. They were able to detect smaller fires than with common MODIS approach, but Sentinel-2 based products have lower temporal resolution and consequently are more affected by cloud/cloud shadows.  visually created using BAMS (Burned Area Mapping Software) methodology \citep{roteta_development_2019}, which consists of a trained classification to detect burned areas between images from two dates\footnote{Available here: \url{https://climate.esa.int/en/projects/fire/data/}}.

Fire studies on Madeira, Spain \citep{navarro_evaluation_2017}. Sentinel-2 data (5 days, 10 m resolution) for pre- and post-fire image assessments (sometimes just two). The framework can be used for the assessment of many other burnt areas globally. Enabling an extremely unprecedented perspective with a unique set of accurate, robust, timely and easily accessible information. No real measurement of accuracy provided.

Classification of burn severity for wildfire in Spain using Sentinel-2 \citep{fernandez-manso_sentinel-2a_2016} (with NBR). Superiority of red-edge spectral indices (particularly, Modified Simple Ratio Red-edge, Chlorophyll Index Red-edge, Normalized Difference Vegetation Index Red-edge) over conventional spectral indices. Fisher’s Least Significant Difference test confirmed that Sentinel-2A MSI red-edge spectral indices are adequate to discriminate four burn severity levels.

\paragraph{Problems with Sentinel 2 Data} \

General problems associated with the resolution of the datasets (10 - 20 m). The radial structure of FIA field plots overlaps with multiple pixels and sometimes the forest edge. Relatively new, so does not have the high temporal value as landsat. Will probably fail to distinguish tree phenology (e.g. growth stages) and can reach a spectral saturation point if biomass is too high.

Papers:

Bamboo forest in China: Seasonality, different growth phenomena in different years. Correlation between spectral bands and biomass varies within a period of months. Biomass calculation based on DBH and age \citep{chen_exploring_2019}. Also used RF to evaluate key variables. \

\paragraph{Sentinel-2 cleaning} \

The Sen2Cor atmospheric correlation processor can be used to conduct atmospheric correction. The Sen2Cor processor was developed for formatting and generating Sentinel-2 Level-2A products. The processor is freely available from the European Space Agency website\footnote{Available here: \url{http://step.esa.int/main/third-party-plugins-2/sen2cor/}}. \

\paragraph{Sentinel-2 estimating AGB} \

Tested the ability of Sentinel imagery (Sentinel-1 (SAR) + Sentinel-2) for the retrieval and predictive mapping of aboveground biomass of mangroves and their replacement land uses (Mangrove Forest, Philippines; \cite{castillo_estimation_2017}). Developed biomass prediction models through the conventional linear regression and novel Machine Learning algorithms (SAR raw polarisation backscatter, multispectral bands, vegetation indices, canopy biophysical variables). Model based on biophysical variable Leaf Area Index (LAI) derived from Sentinel-2 was more accurate in predicting the overall aboveground biomass (RMSE 27.8 – 28.5 Mg ha$^{-1}$). Among the Sentinel-2 multispectral bands, the red and red edge bands (bands 4, 5 and 7), combined with elevation data, were the best variable set combination for biomass prediction. The red edge-based Inverted RedEdge Chlorophyll Index had the highest prediction accuracy among the vegetation indices. All modelling tasks were implemented using IBM SPSS Statistics version 23 (IBM, USA) and the Waikato Environment for Knowledge Analysis (WEKA, version 3.8.0, The University of Waikato, NZ). The WEKA software is a collection of machine learning algorithms \citep{hall_weka_2009}. To assess if the correlation with biomass and prediction error from the linear models can still be improved, the set of predictors from the linear models with the highest r and lowest RMSE for each part was further subjected to 17 machine learning algorithms available in the WEKA machine learning software. The model/algorithm with highest r and lowest RMSE was selected for use in predictive mapping of biomass which was implemented in ArcGIS (version 10.3.1, ESRI, USA). Four biomass predictive maps were produced which were derived from Sentinel-1 SAR channels, Sentinel-2 bands, Sentinel-2 vegetation index, and Sentinel-2 vegetation biophysical variable \citep{castillo_estimation_2017}.

\newpage

\subsection{LiDAR}

LiDAR data is the new standard when it comes to estimating aboveground bioass (AGB). Common accuracy assessments workflows calculate AGB via vegetation/canopy height and measure accuracy by comparing it to AGB derived from forest plots. For these procedures everything > 2 m is typically classified as canopy (Jonathan Kane, 29 April meeting). Identification of individual trees is only possible if resolution matches the size of the individual canopy (< 1m, Van Kane, 29 April meeting). LiDAR has proven to be useful in estimating vegetation metrics (basal area and stem density with R² values of 0.86–0.95 across multiple studies, \cite{zald_influence_2014})

Recent paper with Jonathan and Van Kane:

They used a Carbon Monitoring System (CMS) to produce annual estimates of aboveground biomass (AGB) using Random Forests (RF) for a regional and landscape scale. Field plots (mostly FIA) with self calculated AGB as a response variable to predict AGB from LiDAR derived canopy height and density information (R² = 0.8, RMSE = 115 Mg ha$^{-1}$, Bias = 2 Mg ha$^{-1}$). A stratified random sample of AGB pixels from landscape-level AGB maps then served as training data for predicting AGB regionally from Landsat image time series variables processed through LandTrendr. Climate metrics calculated from down-scaled 30 year climate normals were used as predictors for both models (landscape and regional), as were topographic metrics calculated from elevation data; these environmental predictors allowed AGB estimation over the full range of observations with the regional model (R² = 0.8, RMSE = 152 Mg ha$^{-1}$, Bias = 9 Mg ha$^{-1}$), including higher AGB values (> 400 Mg ha$^{-1}$) where spectral predictors alone saturate \citep{hudak_carbon_2020}.

\paragraph{Combination of LiDAR and other remotely sensed information for biomass estimation} \

A) \textbf{LiDAR and QuickBird} composite image did not improve AGB estimation in mixed coniferous forests in California; LiDAR data alone provided a better performance \citep{hyde_mapping_2006}.

B) \textbf{LiDAR and Hyperspectral} combination has lower accuracy than LiDAR alone in tropical forest Costa Rica, but are expected to improve the performance if a vegetation classification can be achieved \citep{clark_estimation_2011}.

C) \textbf{LiDAR and Synthetic Aperture Radar (SAR)}. A paper provides an overview table for all combinations and their output accuracies (\autoref{fig:lidar-sar-overview}, \cite{kaasalainen_combining_2015}). Upscaling refers to the extrapolation of LiDAR to areas where LiDAR is not available. The implementation of additional data layers increased the accuracy.


\begin{figure}[H]
 \includegraphics[scale=0.35]{../figures/lidarplussar.png}
 \caption{Overview of combinations of LiDAR and radar in research (taken from Kaasalainen et al., 2015)}
 \label{fig:lidar-sar-overview}
\end{figure}


D) \textbf{LiDAR and Landsat}. \cite{matasci_large-area_2018} provide an overview of combination of LiDAR with spaceborne imagery (mainly MODIS \& LandSat, \autoref{fig:lidar-landsat-overview})


\begin{figure}[H]
 \includegraphics[scale=0.3]{../figures/lidarpluslandsat.png}
 \caption{Overview of combinations of LiDAR (air- or spaceborne), and optical imagery to map forest structural attributes (taken from Matasci et al. 2018)}
 \label{fig:lidar-landsat-overview}
\end{figure}



\subsubsection{LiDAR remove noise} 

A) Lastool in QGIS (LASnoise)

B) LiDAR360 3.1 software (GreenValley, Being, China) to remove the noise points floating between the flight altitude and the mangroves. \citep{wang_estimating_2020}.

C) Triangulated irregular network (TIN) densification as a filtering algorithm to deal with complex forest landscapes \citep{zhao_improved_2016}. Improved progressive TIN densification filtering algorithm (IPTD) performs better than other general filtering algorithms (\autoref{fig:iptd}). The strength of 537 the IPTD lies in its ability to retain hilltops and handle break lines and steep slopes. Four parameters are used in the IPTD, i.e., k (neighboring number), r (threshold), 0 (iterative angle), and s (iterative distance). Densifies ground points and accounts for ground surface structure with (upward/downward densification) \citep{zhao_improved_2016}.

\begin{figure}[H]
  \begin{center}
 \includegraphics[scale=0.35]{../figures/iptd.png}
 \caption{Comparison of kappa values (total error, TE) for LiDAR filtering algorithms for 15 sites tested. Lowest value in bold (taken from Zhao et al., 2016)}
 \label{fig:iptd}
  \end{center}
\end{figure}

C) The Fusion\footnote{Available here: \url{http://forsys.cfr.washington.edu/fusion/fusionlatest.html}} software (Windows) used by the USFS introduces filters and smoothing algorithms to create digital surface model. The workflows necessary to create a clean digital terrain model still have to be assessed. While an outlier filter could be used to remove below-ground points the scalability of the approach over larger areas and difficcult topography is questionable. Currently the procedure is to rely on vendor provided DTM's and create a DSM and a CHM in Fusion.

D) PDAL\footnote{PDAL documentation: \url{https://pdal.io/}} offers a wide and specialised library to work with pooint cloud information. Filtering, classification and creation of terrain models can be implemented into a comprehensive script and assures scalability of the approach. Accuracy of the output will be tested against canopy height models provided by the vendors and created in Fusion (currently 'best practice').

\subsubsection{Identifying individual trees vs canopy area approach}

Tree-centric approaches are not accurate enough yet in order to justify a much more hardware intensive calculation. Tree-centric modelling is intruiging because it is based on summing biomasses of individual trees, but until algorithms can detect understory trees reliably and estimate biomass from crown dimensions precisely, areas-based modelling will remain the method of choice \citep{coomes_area-based_2017}.

\paragraph{Canopy height estimates from LiDAR (methods)} \

A) Quantifying australian wheat \citep{walter_estimating_2019}. Point cloud resolution of 90 pts m$^{-2}$ by using sensors mounted on farming vehicle coupled with multispectral sensors to identify vegetation. Canopy height was extracted through percentile algorithm in R. Two step approach: (1) Identifying the 98th percentile of maximum returned height in each scan line and (2) taking the 86th percentile of these values to provide an estimate of overall canopy height. 86th percentile was selected through optimization of Pearson’s correlation coefficient and RMSE between LiDAR derived canopy height and measured canopy height for all sample times. More details in supplementary \citep{walter_estimating_2019}.

B) Honkong forest with thousands of individual tree measurements (DBH, height; \cite{chan_estimating_2021}). LiDAR processed to TIN by extracting only the ground returns. Te extraction and processing were performed in ArcMap with LAStools\footnote{Available here: \url{https://rapidlasso.com/lastools/}} extension and FUSION\footnote{Available here: \url{http://forsys.cfr.washington.edu/fusion/fusionlatest.html}}. The canopy surface was defined using all non-ground returns with height above 2.0 m. The reason of choosing 2.0 m as the threshold was to avoid canopy returns to be mixed with ground returns. Entire 1 ha study area was divided into circular plots with three plot sizes (10, 5 and 2.5 m radius; \cite{chan_estimating_2021}). Field data layout: Circular plots were considered more favorable than rectangular or square plots, since the periphery-to-area ratio was the smallest and thus minimized the number of edge trees \citep{kohl_sampling_2006}. Relevant plot metrics (LiDAR, climate) were derived by the ‘cloudmetrics’ function in FUSION version 3.7. The LiDAR metrics, and its log-transformed metrics were input into stepwise regression model as independent predictors of AGB. Significant predictors were selected (F < 0.5 were entered and F > 1.0 were removed) into the regression model. Tree sets of regression models were generated and the allometric models tended to be linear and normal after logarithmic transformation (old ecology ref available if necessary). Logarithmic transformation increased accuary. Model predicted three parameters : (1) canopy cover by first returns, (2) 95th Height Percentile and (3) median of absolute deviation from mode (MADmode). Accuracy of predication increased with plot size \citep{chan_estimating_2021}.

\newpage

\subsubsection{Common LiDAR point metrics}

A wealth of LiDAR plot metrics can be derived from point clouds (\autoref{tab:lidarmetrics}) and they can even be used do discriminate forest tree species (e.g. with and without leaves; \cite{shi_important_2018}). They are created by using height profiles and point distancing (for detailed table with references see \cite{dong_selection_2017}) and can be grouped in four categories:

1) \textbf{height}  (canopy height distributions within the plot) estimator for carbon and AGB \citep{lim_estimation_2004,patenaude_quantifying_2004}

2) \textbf{intensity} (similar to the height metrics except that they are statistics of the intensity value rather than the height value of the point clouds, only finds application in high resolution LiDAR datasets)

3) \textbf{density} (canopy return density)

4) \textbf{canopy volume} (portray canopy morphology for canopy cover index or leaf area density)


\begin{tiny}
  \begin{table}[hbp]
    \caption{Overview LiDAR derived metrics (taken from Wang et al. 2020)}
    \label{tab:lidarmetrics}
    \begin{tabular}{lp{4cm}p{7cm}l}
      LiDAR & Variable & Definition \tabularnewline
      \addlinespace
      Height &	HMax, HMean, HMedian &	Maximum / Mean / Median heights \\														
      & HSD, HVAR &	Standard deviation heights, variance of heights \\														
      & HSKE, HKUR &	Skewness of heights, Kurtosis of heights	\\													
      & HCV &	Coefficient of variation of height, (Zstd / Zmean) × 100 \% \\														
      & HIQ &	Interquartile distance of percentile height, H75th – H25th	\\													
      & H01, H05, H10, H20, H25, H30, H40, H50, H60, H70, H75, H80, H90, H95, H99 &	Height percentiles. Point clouds are sorted according to the elevation. HX is the Xth percentile of height. There are 15 height percentiles metrics from 1 \% to 99 \% height. \\ \addlinespace											
    Density &	D01, D02, D03, D04, D05... &	Canopy return density. Point clouds are divided into slices with the same interval from low to high elevations. DX is the number of canopy return points in the Xth slice compared to the total points.	\\			\addlinespace												
    Canopy volume &	CC1.3 &	Canopy cover above 1.3 m, n\_veg1.3 / n\_total \\														
    & CCmean &	Canopy cover above mean height, n\_vegmean / ntotal \\														
    & CRR	& Canopy relief ratio (Hmean - Hmin) / (Hmax - Hmin) \\														
    & CTHK &	Canopy thickness, H90th-H10th. (new in \cite{wang_estimating_2020})	\\													
    & LADX &	Leaf area density. Point clouds are divided into slices with the same interval from low to high elevations. LADX is the valid leaf area density in the Xth slice \citep{kamoske_leaf_2019}	\\												
    & a, b &	The scale parameter a (shape of vertical distribution) and shape parameter b (increase/decrease of distribution breadth) of the Weibull density distribution fitted to the foliage profile \citep{liu_estimating_2018} \\				 									
    \end{tabular}
  \end{table}
  \end{tiny}



\subsubsection{Upscaling LiDAR with Sentinel-2} \

LiDAR upscaling of field plots (point), UAV-LiDAR strip (line) data and Sentinel-2 imagery (polygon) based on a point-line-polygon framework for AGB estimation in a mangrove forest \citep{wang_estimating_2020}. Field plots were linked to UAV-LiDAR plots with a random forest model and then extrapolated to all UAV-LiDAR grid cells. UAV-LiDAR serves as a linear bridge between forest plots and sentinel data (polygon). For method comparison, a traditional model was also constructed using only field plots and Sentinel-2 imagery. Since the validation plots were gradually added to the G-S2 (without LiDAR) model, there were not enough observations to validate the model performance with an independent subset. Therefore, a 10-fold cross-validation method was employed and repeated 10 times as suggested by Ghosh and Behera (2018). The same 10-fold cross-validation process that was iterated 10-times was also applied to the G-LiDAR-S2 model to obtain cross-validation accuracy. A variable selection process was also conducted via the backward feature elimination method prior to the final estimation due to the large number of Sentinel-2 (32) and UAV-LiDAR variables (53) input. As usual, a model constructed from a small number of variables is more interpretable, and eliminating irrelevant and highly correlated variables may improve the predictive power \citep{gregorutti_correlation_2017}. The backward feature elimination approach is based on the random forest algorithm and compares the cross-validated prediction results of model as a proportion of the predictors is eliminated. This method was implemented by the rfcv function in the random Forest package and replicated 100 times with 5-fold cross-validation to get the optimal variables \citep{pham_monitoring_2017}.

AGB estimates were assessed using in-dependent validation samples by comparing the predicted to observed values using the coefficient of determination R², root mean square error (RMSE) and RMSE expressed as a percentage of the observed mean (RMSE\%) \citep{matasci_large-area_2018,pham_monitoring_2017}.

RF has been widely used in biomass upscaling approaches \citep{matasci_large-area_2018,pham_monitoring_2017, huang_integration_2019, ghosh_aboveground_2018}.

\paragraph{Upscaling LiDAR with GeoEye-1} \

GeoEye-1 image and LiDAR data were segmented using region growing approach to delineate individual tree crowns; and the segmented crowns of tree were further used to establish a relationship with field measured carbon and total tree height \citep{wangda_species_2019} \

Upscaling of biomass and carbon estimates by tree-centric approaches are less accurate \citep{coomes_area-based_2017}, but studies on the upscaling carbon estimates by species stratification using VHR and LiDAR in smaller areas to a landscape level are limited \citep{latifi_stratified_2015} \

Field plots (DBH (> 10 cm), tree height, species and crown diameter), calculated biomass with mangrove-specific equation and converted to carbon stock using IPCC conversion factor. GeoEye-1 data to delineate trees and canopy height model to estimate individual height. eCognition for object based image analysis and resulting species separation with tree height. Training dataset comprising 70 \% of the identified trees on the image from the field work (296 trees) was used to train the sample tree species, while the remaining 30 \% was used for validating the classification result. Regression analysis to model relationship between AGB (dependent variable, from allometric equation) and tree height and crown projection area (2 independent variables). Upscaling from reference carbon to RapidEye image: Principal component analysis (PCA) was performed on the image, and the first principal component (PC1) and the individual raster values of RedEdge and near-infrared (NIR) bands were also used to investigate the relationship between reference carbon and the spectral reflectance of RapidEye image. Red and NIR bands were used because these bands are sensitive to chlorophyll content in the vegetation and vegetation is related to AGB. Since the dataset obtained was huge, a grid of 100 m × 100 m was created over the study area, and 10 grids were chosen randomly for further analysis. Data were partitioned into 70 \% and 30 \% as training and validation datasets. The aggregated carbon was used as a dependent variable and the derived vegetation indices, i.e. PC1, RedEdge band and the NIR band were used as single independent variables \citep{wangda_species_2019}. \

\newpage

\subsection{Field data}

Application of LiDAR for forest inventory requires field plot data to ground-truth the information. Field plots need to incorporate relevant parameters (volume, basal area, biomass) \citep{hudak_carbon_2020}. FIA plot data provide an unbiased, systematic sample of forest conditions in space and time and are more applicable over larger areas and for successive effects such as climate change and forest regeneration rates \citep{tinkham_applications_2018}. LiDAR verification plots follow the 'Forest Inventory and Analysis National Program' (FIA) protocol\footnote{Sampling techniques used: \url{https://www.fia.fs.fed.us/program-features/index.php}} and we received plot locations for the Lake Tahoe region.

\paragraph{LiDAR verification plots} \

\begin{itemize}
 \item Allometric: DBH, size classes (e.g. saplings) > height groups, largest tree measured, height to live crown, crown ratio, crown width, age data sparse and based on 1-2 cores
 \item plot center GPS using Javad
 \item plot date and size
 \item Ancillary data: Slope, ground cover, vegetation cover by type (e.g. shrub, forb, etc), modal vegetation height by different types of vegetation, fuel models, fuels data, seedlings, site history (e.g. plantation, if there was a fire, etc)
\end{itemize}

Forest plots are triangles with 4 circular subplots (\autoref{fig:fiaplot}), we can assume they are representative of 1 ha of forest (Van Kane, 29 April meeting). There is a spatial mismatch between the 7.3 m radius, round configuration of an FIA subplot and 30 m × 30 m square Landsat pixels \citep{tinkham_applications_2018}. Inevitably, the four subplots will intersect a different number of pixels and in varying proportions.

Criteria to match LiDAR with FIA plots \citep{hudak_carbon_2020}:

\begin{itemize}
 \item fixed-area plots
 \item geo-referenced with a GNSS capable of differential correction
 \item established within ±3 years of an overlapping LiDAR collection
 \item not disturbed in the time between field and LiDAR data collections
\end{itemize}


\begin{figure}[H]
 \begin{center}
 \includegraphics[scale=0.5]{../figures/fiaplot.png}
 \caption{FIA sampling plot layout. a) generated canopy height model from LiDAR and b) landsat 30m imagery overlay (taken from Hudak et al., 2020)}
 \label{fig:fiaplot}
 \end{center}
\end{figure}


\subsubsection{Biomass estimation in the field}

Collection of a large number of biomass reference data at the plot level is time-consuming and labor-intensive. It is only suitable for a small area and cannot provide the spatial distribution. However, this kind of data is a prerequisite for developing biomass estimation models \citep{lu_survey_2016}. Allometric models are most common, but require data about soil, land use history and climate influence \citep{clark_tropical_2012}.

Two methods:

1) Use data of national forest inventories. Calculate with volume expansion factor (VEF), average wood density (WD), biomass expansion factor (BEF) \citep{brown_biomass_1989, lehtonen_biomass_2004, wang_uncertainties_2011}: \

\begin{equation}
AGB (kg/ha) = volume (m3 / ha) * VEF * WD * BEF + e
\label {eq:agb}
\end{equation}

2) AGB can be calculated from field plots using equations from Fire and Fuels Extension (FFE) of the Forest Vegetation Simulator (FVS\footnote{FVS documentation: \url{https://www.fs.fed.us/fmsc/ftp/fvs/docs/gtr/EssentialFVS.pdf}}). These equations are based on a series of regional volume and biomass equations. The aboveground portion of the live and standing dead trees were summed to a single, plot-level AGB value; the belowground portion of the trees and non-tree species were excluded from the AGB estimates. These plot-level AGB estimates were used as the response variable for a landscape model \citep{hudak_carbon_2020}.

\newpage

\subsubsection{Problems with field data (taken from \cite{lu_survey_2016})}

\begin{itemize}
 \item tree variables, including sampling, measurement, recording and grouping errors when tree variables such as DBH and height are measured
 \item conversion coefficients and models including variation of conversion factors from volume to biomass and then to carbon, inappropriate selection and usage of allometric models for relationship of tree volume and DBH and height, and incorrect regression models relating forest biomass/carbon to spectral variables
 \item uncertainties of spectral values due to unbalanced platforms, scanner motions, poor atmospheric conditions, and slope; inappropriate spatial interpolation methods for geometrical and radiometric corrections, and incorrect methods for image enhancement and analysis
 \item sample plot locations, including global positing system (GPS) coordinates used to locate the sample plots, geometric correction and the uncertainties due to mismatch of sample plots with spatial resolutions of remotely sensed data
 \item differences in sizes of sample plots and image pixels, disagreement between remotely sensed data and plot observations when portions of trees on boundaries are outside plots although both sample plots and pixels have the same spatial resolutions
 \item temporal differences between field plot measurements and remotely sensed data
\end{itemize}

Depending on the protocol and the quality of the Global Navigation Satellite System (GNSS) receiver used in the field; the three peripheral subplots, while systematically laid out from the center subplot by consistent distances (36.6 m) and bearings (120◦, 240◦, 360◦) are usually not georeferenced, making them more subject to locational inaccuracy due to additive errors in accounting for horizontal distance on slopes and for magnetic declination on compass azimuths \citep{zald_influence_2014}. \

\newpage

\subsection{Forest classification}

Van Kane (meeting Apr 29):
Forest service cannot reveal plot locations, only if project output is open access (ideally uni projects). Suggestion: Use Gradient nearest neighbours (GNN) so nearest plot imputes tree list.

\paragraph{NLCDB} \

The National Land Cover Database (NLCD) is updated every five years and stands as the definitive land cover database for the United States\footnote{NLCDB legend: \url{https://www.mrlc.gov/data/legends/national-land-cover-database-2016-nlcd2016-legend}}.. The latest iteration is NCLD 2016. It contains 28 different land cover products characterizing land cover and land cover change across 7 epochs from 2001-2016, urban imperviousness and urban imperviousness change across 4 epochs from 2001-2016, tree canopy and tree canopy change across 2 epochs from 2011-2016 and western U.S. shrub and grassland areas for 2016. NLCD 2019 is scheduled to be released in mid-2021.


\paragraph{CALVEG} \

Vegetation mapping has been completed for all of the National Forest lands of Pacific Southwest Region. Updates and map improvements are scheduled as part of the Monitoring program (aim is to update layers in 15 year intervals). Through cooperative mapping projects, all ownerships within North Interior, Northern Sierras, North Coast and Montane, \& South Coast and Montane CALVEG Zones have been completed. Classification processes include detailed field studies and literature reviews\footnote{CALVEG documentation: \url{https://www.fs.fed.us/emc/rig/documents/protocols/vegClassMapInv/EVTG_v2-0_June2015.pdf}}. A map status of the CALVEG Ecological zones has been provided by the USFS (\autoref{fig:calveg}). The dataset can be downloaded as polygon shapefiles for the different zones.


\begin{figure}[h!]
 \begin{center}
 \includegraphics[scale=0.15]{../figures/calveg.png}
 \caption{Current status of the CALVEG vegetation classification program for California (USFS)}
 \label{fig:calveg}
 \end{center}
\end{figure}

\paragraph{FRID} \

The fire return interval departure (FRID) analysis quantifies the difference between current and presettlement fire frequencies and downscales the CALVEG classification into 32 dominant vegetation groups. It receives an annual update (just released the 2020 version two weeks ago). This polygon layer consists of information compiled about fire return intervals for major vegetation types on the 18 National Forests in California and adjacent land jurisdictions. Comparisons are made between pre-Euroamerican settlement and contemporary fire return intervals (FRI). Current departures from the pre-Euroamerican settlement FRIs are calculated based on mean, median, minimum, and maximum FRI values{FRID documentation: \url{https://www.fs.fed.us/r5/rsl/projects/gis/data/FRID/FRID_Metadata.html}}.



\newpage

\subsection{Landsat}

Landsat data (mainly thematic mapper (TM)

The deployment of Landsat imagery to refine the machine learning process has been discussed, but any form of implementation still requires testing. While the Landsat data comes at a coarser resolution than the Sentinel-2 imagery (\autoref{tab:landsat}), it offers a much higher temporal resolution reaching back to 1984. Landsat imagery became publicly available in 2008 and resulted in great interest by researchers. Pixel based image interpolations have been developed recently and are best pratice in generating annual gap-free image tiles for the period of interest (e.g. growing season). This can be achieved by a best available pixel approach (BAP, \cite{white_pixel-based_2014}) in combination with breakpoint detection procedure (Composite2Change, \cite{hermosilla_integrated_2015}). Normalized Burn Ratio (NBR, \cite{key_landscape_2005}) derived from shortwave infrared bands (SWIR) are currently serving as the best reference indices to assess forest disturbance \citep{kennedy_detecting_2010}. Based on the gap-free tiles forest recovery times after logging and wildfire events can be estimated \citep{white_nationwide_2017}. The output can be used to predict biomass regeneration of burned areas (30 m). Further, it may allow us to label forest types (from CALVEG) with their expected regeneration capabilities to return to a pre-fire state. Time series analysis can be an important indicator to estimate the severity of fire damage and help predict forest stands where post-fire LiDAR information is unavailable.

Available Landsat Data:

\begin{itemize}
 \item Landsat 8 Operational Land Imager (OLI): April 2013 to present
 \item Landsat 7 Enhanced Thematic Mapper Plus (ETM+): July 1999 to present
 \item Landsat 5 Thematic Mapper (TM): March 1984 to May 2012
 \item Landsat 4 Thematic Mapper (TM): July 1982 to December 1993
\end{itemize}

An API for the Landsat data is available\footnote{Access here: \url{https://espa.cr.usgs.gov/static/docs/api-readme.html}}. USGS Landsat archive: L1T products are systematically corrected for radiometric, geometric, and terrain distortions. Preference for Landsat-5 over Landsat-7 for best available pixel analysis (details below, \cite{white_pixel-based_2014}. eDART, an Ecosystem Disturbance and Recovery Tracker system for monitoring landscape disturbances has been developed for Landsat imagery \citep{koltunov_edart_2020}, but they do not provide a tool they publicly share (VP, 28 May).

\begin{small}
  \begin{table}[h!]
    \caption{OLandsat 8-9 Operational Land Imager (OLI) and Thermal Infrared Sensor (TIRS; \cite{usgs_what_2018}}
    \label{tab:landsat}
    \begin{tabular}{cllr}
      Band & Wavelength (µm) & Resolution (m) & Resolution (m) \tabularnewline
      \addlinespace
      Band 1 & Coastal aerosol &	0.43-0.45	& 30 \\
      Band 2 & Blue &	0.45-0.51	& 30 \\
      Band 3 & Green &	0.53-0.59	& 30 \\
      Band 4 & Red &	0.64-0.67	& 30 \\
      Band 5 & Near Infrared (NIR) &	0.85-0.88 &	30 \\
      Band 6 & SWIR 1 &	1.57-1.65	& 30 \\
      Band 7 & SWIR 2 &	2.11-2.29	& 30 \\
      Band 8 & Panchromatic &	0.50-0.68 &	15 \\
      Band 9 & Cirrus &	1.36-1.38 &	30 \\
      Band 10 & Thermal Infrared (TIRS) 1 &	10.6-11.19 & 100 \\
      Band 11 & Thermal Infrared (TIRS) 2 &	11.50-12.51 &	100 \\
    \end{tabular}
  \end{table}
  \end{small}



LandTrendr provides a set of spectral-temporal segmentation algorithms that are useful for change detection in a time series of moderate resolution satellite imagery (\autoref{fig:landtrendr}; primarily Landsat) and for generating trajectory-based spectral time series data largely absent of inter-annual signal noise. Can be used to assess forest regeneration over larger timescales. They provide a github repository evaluating how to extract the data from e.g. Google Earth(FVS)\footnote{Access here: \url{https://emapr.github.io/LT-GEE/landtrendr.html}}.

\begin{figure}[h!]
 \includegraphics[scale=0.5]{../figures/landtrendr.png}
 \caption{Pixel change over updated intervals for the Normalized Burn Ratio (NBR)}
 \label{fig:landtrendr}
\end{figure}


\subsubsection{Normalized Burn Ratio (NBR) for LandSat time series analysis} 

NBR is the recommended spectral index to perform land cover change analysis \citep{key_landscape_2005}. NBR2 is an alternative to highlight water sensitivity in vegetation and may be useful in post-fire recovery studies. NBR2 is calculated as a ratio between the SWIR values, substituting the SWIR1 band for the NIR band used in NBR \autoref{eq:nbr2}. Rasters with calculated NBR2 (LC8NBR2, LE7NBR2, LT5NBR2, or LT4NBR2) may be readily available, but otherwise the procedure can be done starting from Sentinel 4-5 data (1984).

\begin{equation}
NBR2 = (SWIR1 – SWIR2) / (SWIR1 + SWIR2)
\label {eq:nbr2}
\end{equation}


\paragraph{Pre-processing of Landsat data} \

A ) \textbf{Cloud \& Shadow:}

Fmask is an object-based algorithm designed to identify clouds and cloud shadows, as well as clear land and water pixels, snow, and areas of no data (Zhu and Woodcock 2012). Fmask is run on 30 m aggregated TOA reflectance\footnote{Detailed method: \url{https://www.l3harrisgeospatial.com/docs/calculatecloudmaskusingfmask.html}}.

B) \textbf{Surface reflectance correction:}

The Landsat Ecosystem Disturbance Adaptive System (LEDAPS) is used to generate surface reflectance values. LEDAPS produces top-of-atmosphere (TOA) reflectance from Landsat TM and ETM+ digital numbers (DN) and applies atmospheric corrections to generate a surface reflectance product. LEDAPS applies the dark dense vegetation method of Kaufman et al. (1997) to estimate aerosol optical thickness (AOT) directly from the imagery and the AOT is one of the inputs used in the 6S radiative transfer model. The LEDAPS surface reflectance output includes an AOT map derived from the Landsat TM or ETM+ blue band commonly referred to as opacity. New standard LaSCR instead of LEDAPS? LaSRC is based on the 6S radiative transfer model and a heritage from the MODIS MCD09 products as well as the earlier LEDAPS algorithm implemented for Landsat-5 and Landsat-7.

\paragraph{Time series analysis for Landsat imagery} \

The process is a multi-method approach, introducing recent developments (pixel based compositing) to achieve the most up to date analysis of landsat information mainly developed around a team of Canada based scientists (Hermosilla, White, Wulder).

A) \textbf{Best available pixel analysis} (BAP; \cite{white_pixel-based_2014})

Four scores were calculated for each pixel. Sensor and Day-of-the-year score (DOY) were calculated at the image level (i.e., all pixels within the image receive the same score), whilst the cloud/cloud shadow and opacity scores were unique to each pixel. Results for BAP analysis in Canada show 83 \% of pixels have a BAP within ± 30 days of a target DOY (here: central day of growing season). For the annual image composites in Saskatchewan, 29 \% of pixels had observations from within ± 30 days of August 1 for all 15 years considered, whilst 74 \% of pixels have 13 or more years of observations within the target date range. When cloud cover exceeds 70 \%, images are difficult to geometrically correct due to obscured ground control points \cite{white_pixel-based_2014}.

B) \textbf{Filling gaps in BAP with breakpoint analysis} (Composite2Change; \cite{hermosilla_integrated_2015})

Characterisation of trends in pixel series. A breakpoint represents a change in the temporal development of a pixel's values through time. Robust identification of breakpoints enablesthe assignment offinal proxy values to pixels with missing observations, as well as enabling change events, and the year in which theevent occurred, to be correctly identified. The breakpoint detection pro-cess is performed over the Normalized Burn Ratio (NBR; \cite{key_landscape_2005}) pixel series, which has been demonstrated as sensitive and con-sistent for the retrieval of disturbance events over forest environments \citep{kennedy_detecting_2010}. Once breakpoints (temporal) have been identified us contextual analysis for spatial correlation. The pre-infill process of data gaps may result in spatially discordant disturbance events labeled with an incorrect year for change. If we consider discrete events, such as a wildfire, the information need is to ensure that these change events are allocated to the correct year \citep{hermosilla_integrated_2015}.

Analysis based on BAP and Composte2Change \citep{hermosilla_regional_2015}

Set of spectral metrics are computed for selected bandsand indices: average of the spectral values of the objects before thechange event, average and standard deviation after the change event,and range, average and standard deviation of the values of the pixelseries for the spectral bands 3, 4, 5, and 7, and for the indices NBR, and Brightness, Greenness and Wetness components from the TasseledCap. Most important predictors within the trend analysis metrics (e.g. average change magnitude,  standard deviation post change).

Method for entire Canada \citep{hermosilla_mass_2016}

The annual image composites were created by considering as candidate images all available Landsat Thematic Mapper (TM) and Enhanced Thematic Mapper Plus (ETM+) images (more than 81,000) from the 1285 scenes (path/rows) of the Landsat Worldwide Referencing System (WRS2) in the USGS archive that covered at least part of the terrestrial area of Canada, had less than 70 \% cloud cover, and were acquired within a date range defined as 1 August ± 30 days from 1984 to 2012. The date 1 August (Julian day 213) was designated as the central target acquisition date due to its correspondence with the growing season for the majority of Canada’s terrestrial area. Change detection overall accuracy was 89 \%. Change attribution overall accuracy was 92 \%, with higher accuracy for standreplacing wildfire and harvest. Changes were assigned to the correct year with an accuracy of 89 \%. \

Nationwide forest regeneration study after logging and wildfire (Canada; \cite{white_nationwide_2017})

Identified national trends in forest disturbance and recovery by disturbance type (1985–2010). 57.5 Mha of Canada's forests were disturbed by wildfire (71 \%) and harvest (29 \%). First national spatially-explicit map of harvesting in Canada at a 30 m resolution. Greater variability in annual area disturbed by wildfire compared to harvest. Spectral recovery metrics indicate that vegetation returns following disturbance via an NBR based approach (\autoref{fig:nbrtimeseries}).


\begin{figure}[H]
  \begin{center}
 \includegraphics[scale=0.65]{../figures/nbrtimeseries.png}
 \caption{Schematic of NBR recovery metrics: ΔNBR-regrowth, Recovery Indicator (RI), and year of recovery (Y2R) (taken from White et al., 2017)}
 \label{fig:nbrtimeseries}
  \end{center}
\end{figure}

Papers:

Landsat time series predictors and information of disturbance eventsfrom 1984 to 2016 were obtained from gap-free Landsat composites,created using the Composite2Change (C2C). Specifically,  summer  image  composites  (August1 ± 30 days) were created through a best available pixel (BAP) selection process which accounted for distance to clouds, atmospheric con-tamination, as well as acquisition sensor. Spectral indices (bold performed best): Tasseled Cap Brightness (TCB), Greenness (TCG),Wetness (TCW), and the NBR \citep{bolton_optimizing_2020}.

Annual time series of gap-free, surface reflectance composites and the detection, delineation and characterization of annual forest changes. Detected forest changes were attributed to a change type (i.e. fire, harvest, road and non-stand-replacing disturbance) following a random forest classification model based on their spectral, geometrical and temporal characteristics. To avoid potential noisy information at boundaries, samples are 45 m away from polygon boundaries.This figure appears in colour in the online version of Forestry. In other words: samples only taken further within the polygon \citep{wulder_satellite-based_2020}.

Jonathan Kane paper \citep{kolden_mapped_2012}. Characterized unburned area within fire perimeters by fire size and severity, characterized distance to an unburned area across the burned portion of the fire, and investigated patch dynamics of unburned patches within the fire perimeter. From 1984 through 2009, the total area within the fire perimeters that was classified as unburned from ΔNBR was 37 \% for Yosemite, 17 \% for Glacier, and 14 \% for Yukon-Charley.

The complex biophysical environments and vegetation characteristics, e.g. phenology, species composition, growth phase, and health – will affect vegetation spectral signatures; thus, biomass estimation models based on optical spectral features cannot be directly transferred to different study areas for biomass mapping \citep{foody_predictive_2003,lu_aboveground_2005}.

Combination of Landsat and land cover to estimate AGB in Uganda \citep{avitabile_capabilities_2012}. A regression tree-based model (Random Forest) produces good results (cross-validated R² 0.81, RMSE 13 T ha$^{-1}$) when trained with a sufficient number of field plots representative of the vegetation variability at national scale. Specific limitations are mainly related to saturation of the optical signal at high biomass density and cloud cover, which hinders the compilation of a radiometrically consistent multi-temporal dataset. Land cover data increases the model performance because it provides information on vegetation phenology.

\newpage

\subsection{Other relevant datasets}


\paragraph{Synthetic aperture radar (SAR)} \

Most radar-based biomass estimation studies use L-band SAR data, especially the ALOS PALSAR L-band data. The SAR C-band data have not been extensively used because of the C-band’s inability to capture forest biomass features. In summary, it is difficult to use radar data for distinguishing vegetation types \citep{lu_aboveground_2012} because radar data reflect the roughness of land cover surfaces instead of the difference between the vegetation types, thus resulting in difficulty of biomass estimation. The speckle in radar data is another problem affecting its applications. Properly employing filtering methods to reduce noise and outliers in InSAR data is needed to improve the vegetation height estimation performance \citep{lu_survey_2016}.

\paragraph{NASA-GEDI LiDAR} \

GEDI has the highest resolution and densest sampling of any LiDAR ever put in orbit (25 m to 1 km resolution). It has been used in an upscaling study of forest biomass in China \citep{chen_improved_2021}. However, satellite was launched in 2018 and only designed to operate for 2 years, will be wrapped up in 2021\footnote{Project website: \url{https://gedi.umd.edu/}}.

Papers:

Comparison of biomass estimates for 3 satellites (GEDI, ICESat-2 and NISAR) over Sonoma county in California \citep{duncanson_biomass_2020}

GEDI and ICESat-2 were simulated from airborne lidar point clouds, while UAVSAR's L-band backscatter was used as a proxy for NISAR. To estimate biomass for the lidar missions we used GEDI's footprint-level biomass algorithms, and also adapted these for application to ICESat-2. For UAVSAR, they developed a locally trained biomass model, calibrated against the ALS reference map. Each mission simulation was evaluated in comparison to the local reference map at its native product resolution (25 m, 100 m transect, and 1 ha) yielding RMSEs of 57 \%, 75 \%, and 89 \% for GEDI, NISAR, and ICESat-2 respectively. They also test the application of GEDI's biomass modeling framework for estimation of biomass from ICESat-2, and find that ICESat-2 yields reasonable biomass estimates, particularly in relatively short, open canopies \citep{duncanson_biomass_2020}.

ICESat-2 underestimates biomass on average, and this underestimation increases with canopy height, canopy cover, and to a small degree with slope. The comparison between simulated GEDI and ICESat-2 height metrics confirms that at least with respect to GEDI simulations, ICESat-2 underestimates height, and these underestimations are more pronounced in the higher height metrics. A comparison of ICESat-2 simulations from the higher signal photon return rate shows that the signal rate drives much of this error, so in areas where ICESat-2 has little atmospheric attenuation ICESat-2 will likely perform well for forest structure \citep{duncanson_biomass_2020}.

As expected, the highest accuracies were from GEDI's power beam, while accuracies for ICESat-2 depended heavily on the signal photon rate, and NISAR accuracies will depend on the availability of high-quality biomass training data, and be limited to lower biomass forests over relatively flat areas. Nonetheless, we find all three sets of mission simulations promising for biomass \citep{duncanson_biomass_2020}.

\paragraph{NOAA-AVHRR, MODIS, ASTER, Quickbird, IKONOS} \

The use of coarse resolution satellite images such as NOAA-AVHRR, MODIS, etc. for biomass estimation is limited due to the occurrence of mixed pixels and inconsistent accuracy at regional or local scale \citep{wangda_species_2019}. The use of moderate resolution satellite images (e.g. Landsat, ASTER) for AGB estimation is also confronted with the problem of mixed pixels and data saturation in complex biophysical environments \citep{wangda_species_2019}. Quickbird and IKONOS have very high resolution, but are frequently obstructed by cloud cover in tropics \citep{wangda_species_2019}, might be more viable in California.

\paragraph{RapidEye} \

ESA is offering access to the full RapidEye archive for scientific research and application development. Access is only available to submitted proposals that are accepted. 5 m pixel size (RGB, RE and NIR). Overall, RapidEye data are not suitable for AGB estimation, but when AGB falls within 50–150 Mg ha$^{-1}$, support vector regression based on stratification of vegetation types provided good results. Problem for biomass estimates can be fixed incorporating tree height if LiDAR data or stereo image is available (Brasilian Rainforest, \cite{feng_examining_2017}).

\paragraph{ICESat-2} \

Ice, Cloud and Land Evalutation Satellite, 91-day repeat, began its 3-year mission in September 2018. While ATLAS onboard ICESat-2 was primarily designed to determine changes in ice sheet elevation and mass, it will provide information about vegetation that may be used to estimate AGB. ATLAS is a photon counting system, operating in the visible wavelengths, at 532 nm. It generates three pairs of tracks, with each pair approximately 3.3 km apart and each track within a pair separated by 90 m. LiDAR footprints are produced every 70 cm in the along-track direction and measure approximately 14 m in diameter. Given the unprecedented coverage and spatial detail from ICESat-2, translating ICESat-2 measurements to AGB estimates would allow for large-scale AGB and forest carbon assessments.

Paper:

ICESat-2 for mapping forest biomass with deep learning \citep{narine_synergy_2019}. A first set of models were developed using vegetation indices calculated from single-date Landsat imagery, canopy cover, and land cover, and a second set of models were generated using metrics from one year of Landsat imagery with canopy cover and land cover maps. With the extended dataset containing metrics calculated from Landsat images acquired on different dates, substantial improvements in model performance for all data scenarios were noted. The R² values increased to 0.64, 0.66, and 0.67. Comparisons with Random forest (RF) prediction models highlighted similar results, with the same R² and root mean square error (RMSE) range (15 – 16 Mg ha$^{-1}$) for daytime and nighttime scenarios. ICESat-2 profiles, especially with the nighttime scenario (R² = 0.66), highlight the potential for generating a wall-to-wall AGB product with ICESat-2 by adopting a synergistic approach with Landsat optical imagery, canopy cover, and land cover \citep{narine_synergy_2019}.

ICESat-2 in combination with land cover data for mapping AGB in Texas (\autoref{fig:icesat}; \cite{narine_using_2020}). Extrapolation of ICESat-2-derived AGB estimates from segments along the ICESat-2 transect, to 30 m pixels across the study site was carried out with RF, using Landsat and NLCD products. Results are indicative of the utility of ICESat-2 data for characterizing AGB. As more ICESat-2 tracks become available and with the availability of corresponding reference data, an improved understanding of the data and their ability to characterize vegetation structure will be gleaned. Nonetheless, possibilities with the data, including synergistic use with freely available data from other space-based missions, including GEDI, are exciting. Future work will involve the application of the methodology for regional-scale mapping with corresponding uncertainty analyses and an investigation of deep-learning approaches with multi-source data \citep{narine_using_2020}.


\begin{figure}[h!]
 \includegraphics[scale=0.5]{../figures/icesat.png}
 \caption{Regression models for estimating AGB with ICESat-2 data from the strong beam and weak beam (taken from Narine et al., 2020)}
 \label{fig:icesat}
\end{figure}


\paragraph{LISS-3 (ISRO)}

Satellites provide multispectral images at 24 m (LISS-3) and 56 m (AWiFs) meter resolution (\autoref{tab:resourcesat}). IRS data products are free of charge to all data users including the general public, scientific and commercial users\footnote{USGS EROS Archive: \url{https://www.usgs.gov/centers/eros/science/usgs-eros-archive-products-overview}}. EarthExplorer and USGS Global Visualization Viewer (GloVis) can be used to search, preview, and download ISRO data. In EarthExplorer the IRS AWiFS and IRS LISS-3 datasets are located under the ISRO Resourcesat category.

\begin{table}[H]
 \caption{Resourcesat Sensor Specifications}
 \label{tab:resourcesat}
 \begin{center}
 \begin{tabular}{lrll}
Sensor & AWiFS & LISS-3
\tabularnewline
\addlinespace
Number of Bands & 4 & 4 \tabularnewline
Spectral Band 2 (µ) &	0.52 – 0.59 (Green)&	0.52 – 0.59 (Green) \tabularnewline
Spectral Band 3 (µ) &	0.62 – 0.68 (Red)	& 0.62 – 0.68 (Red) \tabularnewline
Spectral Band 4 (µ) &	0.77 – 0.86 (NIR)	& 0.77 – 0.86 (NIR) \tabularnewline
Spectral Band 5 (µ) &	1.55 – 1.70 (SWIR)&	1.55 – 1.70 (SWIR) \tabularnewline
Resolution (m)	& 56 &	24 \tabularnewline
Swath (km) &	740	& 140 \tabularnewline
Revisit Period (days) &	5	& 24 \tabularnewline
 \end{tabular}
\end{center}
\end{table}


\paragraph{Climate data} \

Paper:

Data was used from the North American Regional Reanalysis (NARR) \citep{mesinger_north_2006}, the National Center for Environmental Prediction’s high-resolution combined model and assimilated dataset available eight-times daily 1979-2000 at 32 km resolution. Ecosystem demography model trained with hourly land surface weather data to calculate carbon assimilation rate and transpiration (2 m air temperature, dew point, downward solar radiation, precipitation, soil temperature; \cite{hurtt_beyond_2019}).

Three parameters to account for climatic variations: Temperature seasonality (TS), Long-term Maximum Climatological Water Defcit, and Precipitation Seasonality (Hongkong Forest; \cite{chan_estimating_2021}).

\newpage


\section{Tools}

\subsection{GIS tools}
\label{app:tools}
\subsubsection{Geospatial Data Abstraction Library (GDAL) Usage}

The Geospatial Data Abstraction Library or GDAL, is an open source library specifically developed for working with raster and vector geospatial data. For raster processing, GDAL libraries are implemented in the backend across the majority of geospatial software tools used today including ArcGIS, FME, and QGIS. The power in GDAL is its command line capability for geospatial data processing. GDAL is relatively easy to script/scale, is well doucmented, and works with virtually all major geospatial data types.

For the purposes of this project, we are leveraging GDAL 3.2.2 for raster processing:
\begin{itemize}
    \item Reprojections (\texttt{gdalwarp})
    \item Resampling (\texttt{gdal\_translate/gdalwarp})
    \item Masking (\texttt{gdal\_translate/gdalwarp})
    \item Data type conversions (\texttt{gdal\_translate})
    \item Metadata queries (\texttt{gdalinfo})
    \item Raster calculations (\texttt{gdal\_calc.py})
    \item Rasterization (\texttt{gdal\_rasterize})
\end{itemize}

Vector processing is made available through GDAL via the ogr2ogr command.  Ogr2ogr is primarily utilized for data transformations and basic clipping. More complex operations are handled using PostGIS.

Additionally, we are implementing GDAL's capabilities to create:
\begin{itemize}
    \item Hillshade (\texttt{gdaldem hillshade})
    \item Slope (\texttt{gdaldem slope})
    \item Aspect (\texttt{gdaldem aspect})
    \item Roughness (\texttt{gdaldem roughness})
\end{itemize}

\subsubsection{Point Cloud Data Abstraction Library (PDAL) Usage}

PDAL (2.3.0) is an open library written in C++ for managing and processing point cloud data. Like LASTools in the Windows environment, PDAL offers similar capabilities. PDAL is an easily scripted tool allowing for scaling. At its core, PDAL utilizes JSON configurations called pipelines and allows us to string multiple processes into JSON documents. This method for developing individual complex pipelines for point clouds gives us the control needed to run these processes across myriad cores.  PDAL is also developed to handle varied point cloud data types outside of the traditional ASPRS LAS. This may be important as we begin to generate surfaces from varied sources.

PDAL is implemented for point cloud filtering plus, generation of Digital Terrain Models (DTM) and Digital Surface Models (DSM). In a basic PDAL process we will:
\begin{enumerate}
    \item Refine point clouds into ground and non-ground points
    \item Generate Digital Terrain Model (DTM) interpolation from ground points
    \item Generate Digital Surface Model (DSM) interpolation from highest points
\end{enumerate}

PDAL is not developed specifically for the generation of surface grids (rasters); however, it does provide this capability when generating output in geoTIFF format. For the generation of surface rasters, an interpolation method is necessary to create a uniform surface. PDAL integrates an additional library called, points2grid to accomplish this. Points2grid utilizes the Inverse Distance Weighted (IDW) method for its interpolations. This method is powerful in creating accurate interpolations, but can have limitations. Notably, the IDW method does not interpolate over large areas where data is not present. Specifically, when generating sufaces, this results in regions of 'nodata' where there are insufficient ground points for interpolation.  This is a known outcome and currently addressed by increasing the window size for the IDW to search for neighboring points.  Currently, we are confident in this solution for addressing 'nodata' regions of the surface model; however, we are continuing to research other solutions (e.g. Triangulated Irregular Networks) and additional interpolation tools like GRASS GIS and SAGA GIS.

\subsubsection{PostGIS/PostgreSQL Usage}

PostgreSQL (13.3) is used to manage vector data as tables. PostGIS is an extension for PostgreSQL providing capabilities to manage these tables as geospatial layers. Vector data is uploaded to PostgreSQL using ogr2ogr. This method allows us to directly load 'file geodatabase' file types to PostgreSQL databases without the need to covert to shapefile first. Conversion to shapefile truncates the column names; therefore, this is very useful tool keeping data intact. Utilizing ogr2ogr for uploads also allows us to force all geometries to multipolygon, further cleaning and generalizing the data.

In testing, both with the Calveg and FRID layers were used with the goal of producing clean rasterized data layers for comparison. The layers were not used in this modelling round, however, promising results were obtained in the tests with PostgreSQL/PostGIS and the plan is to implemet those learning in the future. Both the Calveg and FRID required cleaning and correction of invalid geometries. These are large complex data sets containing millions of vertices and complex geometries. PostGIS (2.4) is an excellent tool for handling these types of large operations. Cleaning is a necessary step for upstream processes like rasterization, but also necessary to work with the data properly.  Once clean, we export the tables using ogr2ogr. Using this command as an export provides us the opportunity to build a single unified shapefile.  Working with a single shapefile, although large, permits easy clips of the data using a bounding box. In the future, it is more likely we will skip the export back to shapefile and query regions directly from the PostgreSQL table instead, leveraging the speed and power of properly indexed data.  For now, the process is tested and functioning as expected.

\subsubsection{Vector Rasterization}

Rasterization of vectors is necessary for the machine learning models. If we are doing pixel to pixel comparisons, the vector data must be in the same format.  Rather than rasterizing the entire vector data set, we clip the data in the shapefile as needed and perfrom the rasterization on the fly.  At the time of the conversion to raster we pass the necessary extents and resolution for the output. We've found this method to be quick since the read and storage of vector data is more efficient.

Results from the generation of the DTM and DSM are then used to calculate the Canopy Height Model (CHM).

\subsubsection{Sentinel 2 Handling}

Handling and manipulation of Sentinel-2 data is performed using GDAL. Raw Sentinel data comes in JP2 format and is projected in its corresponding UTM zone. The first operation on Sentinel-2 is to bring all the images into a singular projection, California Albers (EPSG:3310). For the purposes of geospatial operations, the data is converted into GeoTiff format. If needed, Sentinel-2 images are re-sampled into 10m resolution. The re-sampling method uses gdal\_translate to split the pixel, e.g a 20m resolution pixel is split into four new pixels to achieve 10m resolution.

\subsubsection{Pixel Alignment}

In order to have clean pixel sampling, we need to ensure all layers align with each other, pixel to pixel.  This is ensured through several processes:

\begin{itemize}
  \item Projection: All data for this project is developed to be in the same projection with the same origin.
  \item Resolution: Each data set is always forced into a 10m resolution when GDAL commands allow.
  \item Extents:  Extents are always captured the the beginning of a process and reapplied to the outputs.
\end{itemize}


\subsection{Production Data Infrastructure}

While systems like PostGIS and QGIS are essential as exploration and debugging tools for GIS workflows, they suffer from important scale limitations that make them unsuitable for Machine Learning applications of the scope ultimately required by Vibrant Planet. To complement these systems, the team deployed a cloud infrastructure stack centered around a 'data lake' architecture, consisting of the following components:
\begin{itemize}
  \item Amazon S3 as the data storage abstraction layer for both tabular and image data.
  \item A standalone Hive metastore, backed by a Postgres database, enabling the storage of tabular data.
  \item Trino as the distributed compute environment responsible for tabular data processing.
  \item Dask as the distributed compute environment responsible for image data processing.
\end{itemize}

The architecture stack was deployed using Kubernetes running on an Amazon EKS cluster. Dedicated node groups were set up for Trino (backed by T3.large instances) and Dask workers (backed by R5.large instances). Processing the area of interest required a peak of 30 instances running at any one time, with a total estimated run time for the entire data preparation pipeline of under 48 hours. Depending on its complexity, model training may add a significant amount of financial and time cost to these compute requirements.

Image data processing was done using the same GDAL commands developed in the exploration stage, adapted using the pattern of 'embarassing parallelism', where independent tasks were created for each of about 25,000 distinct image files identified in the area of interest. Hive tables were used to manage run metadata (i.e., what files needed processing, or had already been processed), whereas Dask workers were used to complete the processing itself. This design choice makes the processing incremental and easy to resume when faced with inevitable infrastructure errors.

\subsubsection{Data Pre-Processing}

The data processing consisted of the following concrete steps:

\begin{enumerate}
   \item \textbf{Identifying MGRS tiles of interest.} This task was done by leveraging an exhaustive listing of level 1B Sentinel data stored on Google Cloud Storage. This table was imported into the data lake, as no similar metadata file was found for the Amazon instantiation of the Sentinel-2 dataset. While the image listings themselves could not be used (due to Google's version of Sentinel2 containing only the 'rawer' Level 1B data, as compared to the Level 2A data hosted by Amazon), the table proved useful due to its containing an exhaustive listing of all MGRS tiles for which Sentinel data is available, as well as their spatial coordinates. The identification of the 9 MGRS tiles of interest was thus done using a simple SQL filter query against this large metadata file.
   \item \textbf{Identifying Sentinel data-takes of interest.} This was done simply by listing all existing data take files in the the S3 keys corresponding to each bucket.
   \item \textbf{Identifying high quality data takes.} This task involved reading the granule metadata corresponding to each datatake. Because the metadata lists an estimated cloud cover percentage, it was possible to separate out images with less than 35 % cloud cover. The 35 % threshold was identified during the exploratory phase.
   \item \textbf{Reprojecting Sentinel datatakes into a uniform coordinate system.} All Sentinel tiles are provided in the UTM coordinate system. Because the area of interest spans multiple UTM bands, it was necessary to harmonize them through reprojection into the California Albers projection -- a planar coordinate system developed specifically for geographic information relating to state's geography.
   \item \textbf{Clipping reprojected datatakes to uniform grid.} Because datatakes corresponding to multiple MGRS tiles could cover the same area, it was necessary to overlay them to create a composite dataset. The first step in creating the overlay involved clipping each tile to a uniform extent, using square tiles with a side of 40 km (this choice was dictated by memory constraints on individual machines used for the data processing.)
   \item \textbf{Merging clipped datatakes into annual summaries.} Clipped datatakes corresponding to the same grid square and year were merged using a simple noise reduction algorithm. Namely, a median value was taken for each pixel across all datatakes referring to the same location during each year's dry season (to minimize artifacts due to snow and clouds, given that clouds were not removed from the processed images.). Where more than 18 data takes were present, the median was approximated as the median of median values taken across each batch of up to 18 data takes (the batch size was determined empirically, to fit within memory constraints.)
\end{enumerate}

\newpage

\section{Supplementary data layers}

\subsection{Incline Village test area}

As part of the surface development testing, a small region north of Lake Tahoe was chosen to help confirm results (/autoref{fig:AOIlc}. The dataset uses a a point cloud collected by Watershed Sciences In, collected in a two week survey in August 2010. The average first-return density is 11.82 pts m$^{-2}$ and the dataset can be accessed via the OpenTopography database\footnote{Lake Tahoe point cloud: \url{https://portal.opentopography.org/datasetMetadata?otCollectionID=OT.032011.26910.1}}.


\begin{figure}[H]
  \centering
      \includegraphics[scale=0.75]{s3/images/referenceMap.png}
      \captionof{figure}{Lemon Canyon and Lake Tahoe Test Regions}\label{fig:AOIlc}
  \end{figure}

\newpage

\subsection{Machine-learning upscaling for a single Sentinel-2 tile}

We demonstrate that the machine-learning can be deployed readily over an entire Sentinel-2 tile (\autoref{fig:mlsentinel2}, 240 x 310 m$^2$). The CHM for the Lemon Canyon has been upscaled using Sentinel-2 red and near-infrared spectral values acquired during the dry season (15 Apr - 15 Oct 2018). The image (10 m resolution) has been created using composite imagery batches (18) by calculating the median for images with low cloud-obstruction (< 35 \%). The batch size was determined empirically by using the highest possible value before memory capacity was reached.


\begin{figure}[H]
  \centering
  \includegraphics[scale=0.85]{/images/modelResultsScale.png}
  \captionsetup{justification=centering}
  \caption{Example for the machine-learning to be deployed over an entire Sentinel-2 tile (10 m, red \& near-infrared bands) using the Lemon Canyon CHM as a training ground. Color ramp used for visualisation purposes only.}
  \label{fig:mlsentinel2}
 \end{figure}



\subsection{Data package}

Included with this report is a collection of zipped images and data from testing. In the folder, one will find two main sub directories named 'data' and 'images'. The data directory contains all the GeoTiffs (DTM, DSM, CHM) from the testing in Lemon Canyon and the Lake Tahoe Region.  Along with the surfaces are the terrain shaded tiffs (HS) used for visualization purposes.  Surfaces are also broken into two projections: California Albers (EPSG:3310) and Web Mercator (EPSG:3857).  The image directory contains all the terrain images used in the report.  In addition, the asscociated QGIS files used to create these images are included.  Please note, it may be necessary to relink the file paths to make these files work properly.Raster files are not mosaicked, but instead, joined using a a Virtual Raster Tile (VRT) file type. VRT's may be loaded directly into QGIS without the need to load individual raster files


  Results for surface generation in Lake Tahoe Test Region (Incline Village)

  \begin{figure}[H]
    \centering
      \begin{subfigure}{.45\linewidth}
        \includegraphics[scale=0.50]{s3/images/lakeTahoe/googleEarth.png}
        \captionsetup{justification=centering}
        \caption{Google Earth Satellite}\label{fig:taba}
      \end{subfigure}
      \begin{subfigure}{.45\linewidth}
        \includegraphics[scale=0.50]{s3/images/lakeTahoe/DSMfly.png}
        \captionsetup{justification=centering}
        \caption{DSM Dragonfly}\label{fig:tabb}
      \end{subfigure}

      \vspace{0.25cm}
      \begin{subfigure}{.45\linewidth}
        \includegraphics[scale=0.50]{s3/images/lakeTahoe/DTMfly.png}
        \captionsetup{justification=centering}
        \caption{DTM Dragonfly}\label{fig:tabc}
      \end{subfigure}
      \begin{subfigure}{.45\linewidth}
        \includegraphics[scale=0.50]{s3/images/lakeTahoe/DTMtopo.png}
        \captionsetup{justification=centering}
        \caption{DTM OpenTopography}\label{fig:tabd}
      \end{subfigure}
    \caption {Surface Output Visualisations for Lake Tahoe Region (Incline Village)} \label{tab:title}
  \end{figure}


Results for Canopy Height Model (CHM) generation in Lake Tahoe Region (Incline Village)

\begin{figure}[H]
  \centering
    \begin{subfigure}{.45\linewidth}
      \includegraphics[scale=0.50]{s3/images/lakeTahoe/googleEarth.png}
      \captionsetup{justification=centering}
      \caption{Google Earth}\label{fig:taba}
    \end{subfigure}
    \begin{subfigure}{.45\linewidth}
      \includegraphics[scale=0.50]{s3/images/lakeTahoe/CHMfly.png}
      \captionsetup{justification=centering}
      \caption{CHM Dragonfly}\label{fig:tabb}
    \end{subfigure}

    \vspace{0.25cm}
    \begin{subfigure}{.45\linewidth}
      \includegraphics[scale=0.50]{s3/images/lakeTahoe/CHMtopo.png}
      \captionsetup{justification=centering}
      \caption{CHM OpenTopography}\label{fig:tabc}
    \end{subfigure}

    \vspace{0.5cm}
    \begin{tabularx}{\textwidth}{XXXXX}
      \cellcolor{black}\textcolor{White}0 & \cellcolor{darkPurple}\textcolor{White}{10} & \cellcolor{Purple}\textcolor{White}{20} & \cellcolor{Pink}\textcolor{White}{30} & \cellcolor{Yellow}\textcolor{lightGray}{40+ meters}
    \end{tabularx}
    \caption {CHM Output Visualisations for Lake Tahoe Region (Incline Village)} \label{tab:title}

\end{figure}

