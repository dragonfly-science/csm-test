\newpage

\section{Discussion}


\subsection{CHM Accuracy Assessment}

Our canopy height model generated from the raw point clouds using PDAL pipelines to filter and generate DTM and DSM compare very favorably against the other CHM's analysed for the Lemon Canyon test region. The canopy heights calculated fall within the expected height of \textit{Pinus jeffreyi} (< 40 m) and create a virtually identical DSM to the vendor provided version. In fact, we provide evidence that our CHM accounts for higher amount of detail within the ground layer resulting in a more accurate depiction of canopy height in areas with heterogenous topography. While we have high confidence in our CHM based and the LiDAR point cloud the output ultimately requires timely ground-truthing to give a definitive statement about it's accuracy. It is important to note that a point cloud with 8.93 pts / m2 as used for the Lemon Canyon has no implications to accurately depict individual trees or canopy height; however, we are confident that our model provides the best approach within our assessment framework. Further, our PDAL pipelines can be implemented readily in our AWS communication assuring scalability while simultaneously removing the lack of vendor provided DTM or pre-classified point clouds as a limitation for available LiDAR data in California.  

\subsection{Prototype Development}

\subsection{Outlook}
 
While our model only incorporates two vegetation indices derived from 10 - 20 m resolution and raw band information from Sentinel-2, vegetation classification (CALVEG) and topography (aspect, slope) we will continue to expand our label library for the final model by introducing a vast range of other labels such as additional vegetation indices derived from three Sentinel-2 red-edge bands (20 m) which hold important ecological information. 

Further, together with experts at VP we will explore methods to derive tree approximate objects (e.g. watershed analysis) to aid the ground-truthing process and delineate higher level of details in forest entities. It is important to note, that a higher resolution for TAO's will require incorporating higher resolution datasets apart from the Sentinel-2 data (10 - 20 m) and will be associated with a careful implementation process (data ingestion, alignment) and additional expenditures. 

A major challenge for streamlining the datasets (LiDAR, field data, vegetation classification) is the significant temporal gap between the acquisition of these layers. While the cadence for Sentinel-2 data is five days the other data layers are a spatial patchwork dating 11 (LiDAR) and 20 years (CALVEG) back in time and have been assessed during a time period where it was either of ecological interest or convenient to access (e.g. distance to roads, growing season). We expect temporal analysis on Sentinel-2 imagery to help us bridge the gap between temporal heterogenous information and aim to further supplement our data with climate information (e.g. rainfall, temperature) to get a more comprehensive historical framework of the status of California's forest ecosystem.  


\subsection{Further Geospatial Testing}

As noted previously, we are confident with our first generations of a CHM.  Through our testing, we are able to attain similar results to CHM's produced by OpenTopography and Vibrant Planet. PDAL, especially around point cloud filtration, perfromed as planned providing clean, repeatable results. We expect to face challenges as we move from testing to implementation of our model on a greater scale, particularly around automation of point cloud ingestion and detection of projection information. 

As we move forward, we plan to continue to explore better methods of surface interpolation via SAGA and GRASS GIS. PDAL again, has provided us with positive results; however, we know PDAL is not natively handling the surface interpolations and passing this process to an external library. With this being a seperate process, it is worth exploring tools with greater capabilites and methods for surface interpolations. By implementing these tools we are afforded opportunties to explore TIN modelling, spline interpolations, and enhancements to inverse distance weighted (IDW)interpolations. Explorations like these are necessary as we are very likely to encounter point clouds of varying densities where applying the best interpolation method is helpful.

We have not implemented PostgreSQl/PostGIS on a large scale yet for this project, but we do not expect limitations with this tool.

Projection, as expected, is a continuing challenge.  With the variety of datasets from varying sources, we are continally assesing our reprojection methods. Points clouds seem to be a particular challenge as they are often deleivered without useful source projection information. For our testing, this was not a significant issue. We were always able to accurately ascertain the source projection manually. As we upscale our point cloud ingestion, we will further explore methods to automatically detect source projection information.