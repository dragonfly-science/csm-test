\newpage
\section{Introduction}

%the introduction needs introductory text

%The expansion of Vibrant Planet's platform for natural resource management requires high-quality data to guide forestry management in the state of California. Best practice decision-making is currently limited to areas where LiDAR datasets are available. Within this model we provide a proof-of-concept how we aim extrapolate point cloud derived canopy height information to the whole state of California.
%
%The prototype ingests publicly-available data, Sentinel-2 spectral bands, vegetation classification layers, to provide an approximation of relevant information without the deployment of costly LiDAR collection procedures.
%
%This documents gives an overview of the state of this project, a brief breakdown of the methodological framework for the prototype and a literature research - revealing the extent of research considered to be deployed. A detailed documentation for geospatial processes, machine learning concepts and data ingestions via AWS can be found on the linked repositories.



Vibrant Planet has developed a data platform for natural resource management, with
a focus on forestry management. Its
prototype platform for the data-informed planning of forestry interventions is due to be 
launched in the second quarter of 2021. This prototype is currently based on a
fine-scale land-cover model, the
Canopy Height Model (CHM), which is capable of detecting ``tree-approximate objects''. The model is built on 
 high-quality LiDAR (light detection and ranging) data. LiDAR measurements (point clouds) reflect state of the art technology for calculating above-ground biomass \citep{chan_estimating_2021}, and is a powerful tool to derive other phenotypic characteristics based on LiDAR metrics (e.g. canopy density; \citep{chan_estimating_2021}. LiDAR data can outperform traditional synthetic aperture radar (SAR) approaches, which fail to accurately depict vegetation surface information \citep{lu_survey_2016}.  

The model's potential to support data-informed decision-making 
has prompted interest in 
expanding its scope to the entirety of the State of California.
This expansion requires high-quality LiDAR data over the state's spatial extent; however,
a uniform LiDAR dataset does not currently exist for the entirety of the state. A small number of CHMs for the State of California are freely available, but provided layers are lacking transparency about their creation methods. Although Vibrant Planet has existing processes to derive CHMs, their application is limited by the availability of vendor-provided Digital Terrain Models (DTM). At the same time, a significant number of raw-classified point clouds are currently publicly accessible (e.g., from United States Geological Survey, USGS)). These publicly-available point clouds provide an opportunity to develop novel processes to classify points, and create a scalable, replicable, and repeatable approach. 
%The current project was focused on developing and assessing processes to Within this report we will present and evaluate our own workflows to generate CHM to operate independently from current limitations.

Once processes to generate CHMs from raw point clouds are established, the information can be up-scaled by training data layers that extend over the entire State of California. Preferred methods to generate landscape-level datasets for forest monitoring are generally based on 
Landsat imagery \citep{matasci_large-area_2018,pham_monitoring_2017, huang_integration_2019, ghosh_aboveground_2018}, including novel processes that have been developed recently for time-series analysis \citep{white_nationwide_2017, wulder_satellite-based_2020, hermosilla_mass_2016}. While these methodologies are currently limited by the spatial resolution of the Landsat pixels (30~m), some studies have examined the training of satellite information with LiDAR data \citep{latifi_stratified_2015, wangda_species_2019, wang_estimating_2020}. In 2017, the European Space Agency opened the Sentinel-2 image library to the public, offering new opportunities to refine monitoring approaches at higher resolutions (10 to 20~m) and increased band selection. Nevertheless, implementation of the Sentinel-2 datasets pose a significant challenge for data ingestion, reprojection, and cleaning which have yet to be explored. 
%cleaning = data processing?
% add forest fire context?

This report provides an overview of the approach and datasets used to develop a CHM test case and the consecutive upscaling of LiDAR-derived canopy height information via Sentinel-2 imagery. Detailed documentation of geospatial processes, machine-learning concepts and data ingestions via Amazon Web Services (AWS) that were part of this project is available in the appendix and in the linked repositories.
%include link to Appendix

%The current project was based on developing an approach to generate a CHM , including a test case as a proof of concept.  %needs re-wording
%The test case used all currently available LiDAR point clouds for a given region from the Opentopography database\footnote{Opentopography LiDAR database: \url{https://portal.opentopography.org/datasets}}. These point clouds date back to 2010, and vary in resolution, sampling technique, and provider.  
%The overall aim of this project was to provide the closest approximation of relevant information that would generally be obtained by the collection of LiDAR data.  





%test region in Lemon Canyon (California

%
%\subsection{Summary}
%
%The following is a brief summary of the methods and data utilized for the Vibrant Planet Canopy Height Model proof-of-concept. This introduction summary is followed by a detailed overview of the data sources and associated methods from the remote sensing and forestry research community. Herein, we introduce the usage and methods for:
%
%\begin{itemize}
%  \item Sentinel-2 satellite data
%  \item USGS LiDAR point clouds and surface generation for CHM
%  \item LiDAR verification plots data
%  \item Calveg vegetation classification data
%  \item Project scaling 
%\end{itemize}
%
%
%\paragraph{Sentinel-2 data} \
%
%Copernicus Sentinel-2 is a constellation of two polar-orbiting satellites collecting global visible and near infrared imagery.  Data is collected at a five day cadence for any given location. Sentinel-2 data is comprised of twelve spectral bands at a resolution ranging from 10 to 60 m per pixel. 
%
%For the purposes of our project, Sentinel-2 can be used to generate vegetation indices like Normalized Burn Ratio (NBR) and Normalized Difference Vegetation Index (NDVI). These indices \citep{pandit_estimating_2018, wang_estimating_2020} can be correlated with outside vegetation features layers and associated Sentinel-2 bands (near-infrared, red-edge, shortwave-infrared) at resolutions higher (10 - 20 m) than traditionally used Landsat data (30 m). Forest ecologists and geospatial scientists commonly use the NBR (NBR, \cite{kennedy_detecting_2010}) and the NDVI to correlate spectral responses with vegetation features (e.g. biomass; \cite{ghosh_aboveground_2018}) and track forest fires. Particularly the three available red-edge sensors and associated indices are valuable in discriminating the different levels of burn severity in forest ecosystems \citep{fernandez-manso_sentinel-2a_2016}. 
%
%For our initial testing we are specifically employing Sentinel-2 L2A ground reflectance data. Sentinel L2A is available from May 2018 to the present. Not yet incorporated is Sentinel L1C; which dates as far back April 2016. The difficulty in working with the L1C is the level of cleaning needed in order to use this product in our pipeline. Several tools developed by the Sentinel project to explore (e.g. SNAP) and clean (e.g. Sen2Cor) Sentinel-2 data are readily available; however, more sophisticated approaches to analyse time series for land classification \citep{campos-taberner_understanding_2020}, as available for LandSat imagery \citep{white_nationwide_2017, wulder_satellite-based_2020, hermosilla_mass_2016} are yet to be explored and require new workflows to process the data. 
%
%Working with a California-wide Sentinel-2 imagery requires reprojection into a uniform coordinate system and workflows to implement our own gridded tiling system. With these workflows in place, we can use the whole database via S3 and query gap-free imagery with low cloud-obstruction to derive spectral indices which can used for the training process with LiDAR information. Only then can we discover the full potential of Sentinel-2 data for time-series analysis to monitor vegetation disturbance, recovery, and improve existing vegetation classification.
%
%\paragraph{LiDAR} \
%
%%LiDAR measurements (point clouds) are state of the art technology for calculating above ground biomass \citep{chan_estimating_2021}, like tree height estimates in forest ecosystems. LiDAR can outperform traditional synthetic aperture radar (SAR) approaches which fail to accurately depict vegetation surface information \citep{lu_survey_2016}.  The canopy height model (CHM), derived from raw LiDAR point clouds, constitutes the 'heart' of our model and is used to train a machine learning process against satellite pixel (Sentinel-2) information.  There is a small amount of freely available CHM models for the state of California. The data that is available is lacking in transparency about its creation methods or is only available as small downloads. USGS does make a large number of raw classified point clouds publicly accessible, so we decided to develop our own workflows to generate a CHM assuring a scalable, replicable, and repeatable approach to our method.  Large scale access to the data is still an issue; however, the ability to develop our own surface models is straight forward with software like PDAL. For our test case, we receive all currently available LiDAR point clouds for a given region from the Opentopography database\footnote{Opentopography LiDAR database: \url{https://portal.opentopography.org/datasets}}. These point clouds date back to 2010 and vary in resolution, sampling technique, and provider. 
%
%A particular challenge associated with an extensive data source is merging the vendor provided point clouds into a streamlined, scalable process consistent across the entire state. Current workflows at Vibrant Planet rely on vendor provided digital terrain models (DTM) and use the Fusion software to derive a digital surface model (DSM) and a resulting canopy height model (CHM). Since vendor provided CHM are not universally available for all datasets and the workflows to derive these are unknown, we demonstrate our own process to generate a DTM, DSM, and CHM using PDAL (Point Data Abstraction Library). This process enables us to work with the full point cloud database and guarantee replicability with future LiDAR dataset regardless of vendor specific point classification differences. 
%
%Within this document, we provide an accuracy assessment to verify our CHM output against current 'best practice' approaches within Fusion (vendor provided DTM, software calculated CHM) and vendor provided models on the OpenTopography database. Our CHM's are developed to work with an area-based approach, rather than a tree-centric approach. For CHM's, this is the current standard due to LiDAR restriction to detect below canopy/merged trees \citep{coomes_area-based_2017}. Further, available LiDAR-datasets require a higher resolution to be able to delineate individual trees CHM resolutions < 1 m are required (Van Kane, April 29 meeting). One possibility to bridge the gap between area-based and tree-centric approaches could be the creation of tree approximate objects (TAO). These objects can be generated within Fusion using a watershed analysis and the area processor. We work together with Vibrant Planet to generate these outputs and test the viability of training satellite data with TAO information or other forms of ecological entities (e.g. Ecobject\footnote{EcObject documentation: \url{https://buttecounty.opennrm.org/assets/e106ca2a359a122e74e33ef183a0fb4a/application/pdf/EcObjectProductGuide_Final_V1.pdf}}). Further limitations based on the resolution of the Sentinel-2 tiles will be will be discussed within this document.
%
%\paragraph{Field data} \
%
%Field plots are helpful to verify the accuracy of our predictions in areas outside of LiDAR availability and to estimate the quality of the generated CHM. While there is a natural problem fusing pixel information with the radial plot layout \citep{hudak_carbon_2020}, the main problem is the limited availability of geo-referenced field plots and the absence of individually geo-tagged trees. For the initial phase of this project we have been provided with LiDAR verification plots for the Lake Tahoe region. These plots contain information about tree species, DBH, height and traditionally consist of 4 radial plots (FIA \& LiDAR plots). It is unlikely that we will receive exact FIA locations for a non-university project (Van Kane, April 29 meeting). Therefore we need to explore other avenues to either extract most relevant data from available field plots or propose alternative procedures to ground-truth the data. An already established workflow as agreed upon with one of Vibrant Planet's forest ecologist, is to identify dominant trees within individual field plots and verify them against our CHM output. Within this document we also provide CHM generated for the Incline Village which can be used readily by VP to ground-truth the output layers. An alternative to individually ground-truth the data is to artificially create gaps in the LiDAR plots to verify against our CHM once enough confidence in the procedure is established.
%
%\paragraph{Vegetation classification}  \
%
%A coherent layer for forest distribution boundaries is an important label to train the model in order to account for phenological differences in the tree species across the state. For the initial proof of concept we used the extensive Classification and Assessment with Landsat of Visible Ecological Groupings database (CALVEG) which summarizes over 100 vegetation classes for the entire state. The layer is a patchwork of identified vegetation areas from 20+ years of mapping conducted with careful literature research and ground-truthing. A second dataset integrated in our model process, the 'Fire Return Interval Departure Dataset' (FRID\footnote{Documentation here: \url{https://data.sacriver.org/assets/5ca70e8ae658de1d1e0331ff747c3f76/application/pdf/California_FRID_GIS_metadata_11-10-20117.pdf}}), groups CALVEG classification into subclasses.  We use this layer as a mask for non-vegetated surfaces (urban, lakes) in the proof-of-concept. Once we begin to produce state-wide layers, the CALVEG database is expected to become a more powerful predictor accounting for higher amount of detail. We will; however, retain the FRID dataset for future use, since it contains valuable information for historic fires in the area. We have developed workflows to clean, reproject, merge, and rasterize the CALVEG dataset.
%
%\paragraph{Upscaling} \
%
%The upscaling process to translate small area LiDAR derived information to a landscape level is an area of limited research \citep{latifi_stratified_2015} and has primarily been used in aboveground biomass interpolations (\citep{matasci_large-area_2018,pham_monitoring_2017, huang_integration_2019, ghosh_aboveground_2018}) to train GeoEye-1 \citep{wangda_species_2019} or Sentinel-2 imagery \citep{wang_estimating_2020}. A particular challenge in the upscaling process is streamlining a range of different sources for our labels (LiDAR point clouds, vegetation layers, Sentinel-2) including cleaning, filtering and querying a large database which can be updated readily. The proof-of-concept documented this report incorporates a linear regression machine learning process to demonstrate the feasibility of this approach with no refined expectations towards it's accuracy. In the future, the machine learning algorithm will be trained with a vast range of vegetation indices, LiDAR metrics, topographic, climatic and vegetation layers. While a random forest has been widely used in ecology to approximate aboveground biomass estimations \citep{ghosh_aboveground_2018,matasci_large-area_2018, pham_monitoring_2017, huang_integration_2019} we will explore more sophisticated options to optimize this process.
%
%The following section provides an overview of the literature review and methodologies considered. We do not anticipate to use all of the datasets mentioned, but we used them to derive a methodological framework which provides a best available practice approach.



